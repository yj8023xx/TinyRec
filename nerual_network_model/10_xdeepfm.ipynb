{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9e18e0",
   "metadata": {},
   "source": [
    "# xDeepFM\n",
    "\n",
    "<img src=\"../img/xdeepfm.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fe1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f333f1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc8c8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_id': 'movielens',\n",
       " 'num_fields': 25,\n",
       " 'feature_specs': {'movieId': {'source': 'item',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 935,\n",
       "   'index': 0},\n",
       "  'userId': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 22540,\n",
       "   'index': 1},\n",
       "  'timestamp': {'source': 'user',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 2},\n",
       "  'releaseYear': {'source': 'item',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 3},\n",
       "  'movieGenre1': {'source': 'item',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 18,\n",
       "   'index': 4},\n",
       "  'movieGenre2': {'source': 'item',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 18,\n",
       "   'index': 5},\n",
       "  'movieGenre3': {'source': 'item',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 15,\n",
       "   'index': 6},\n",
       "  'movieRatingCount': {'source': 'item',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 7},\n",
       "  'movieAvgRating': {'source': 'item',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 8},\n",
       "  'movieRatingStddev': {'source': 'item',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 9},\n",
       "  'userRatedMovie1': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 882,\n",
       "   'index': 10},\n",
       "  'userRatedMovie2': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 874,\n",
       "   'index': 11},\n",
       "  'userRatedMovie3': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 877,\n",
       "   'index': 12},\n",
       "  'userRatedMovie4': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 871,\n",
       "   'index': 13},\n",
       "  'userRatedMovie5': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 864,\n",
       "   'index': 14},\n",
       "  'userRatingCount': {'source': 'user',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 15},\n",
       "  'userAvgReleaseYear': {'source': 'user',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 16},\n",
       "  'userReleaseYearStddev': {'source': 'user',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 17},\n",
       "  'userAvgRating': {'source': 'user',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 18},\n",
       "  'userRatingStddev': {'source': 'user',\n",
       "   'type': 'numerical',\n",
       "   'vocab_size': 1,\n",
       "   'index': 19},\n",
       "  'userGenre1': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 19,\n",
       "   'index': 20},\n",
       "  'userGenre2': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 19,\n",
       "   'index': 21},\n",
       "  'userGenre3': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 19,\n",
       "   'index': 22},\n",
       "  'userGenre4': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 19,\n",
       "   'index': 23},\n",
       "  'userGenre5': {'source': 'user',\n",
       "   'type': 'categorical',\n",
       "   'vocab_size': 19,\n",
       "   'index': 24}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/movielens/feature_map.json') as obj:\n",
    "    feature_map = json.load(obj)\n",
    "feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02131aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensDataset(Dataset):\n",
    "    def __init__(self, url):\n",
    "        self.df = pd.read_csv(url)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.df.iloc[idx, :-1].values.astype(np.float32), self.df.iloc[idx, -1].astype(np.float32)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc36e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovielensDataset('../data/movielens/data_for_train.csv')\n",
    "test_dataset = MovielensDataset('../data/movielens/data_for_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc8d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9da613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class xDeepFM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feature_map,\n",
    "                 embedding_dim=10,\n",
    "                 hidden_units=[256, 128, 64],\n",
    "                 cin_units=[16, 16, 16]):\n",
    "        super(xDeepFM, self).__init__()\n",
    "        self.feature_map = feature_map\n",
    "        # Embedding\n",
    "        self.embedding = nn.ModuleDict()\n",
    "        for feature, feature_spec in feature_map['feature_specs'].items():\n",
    "            if feature_spec['type'] == 'numerical':\n",
    "                self.embedding[feature] = nn.Linear(\n",
    "                    1, embedding_dim, bias=False)\n",
    "            elif feature_spec['type'] == 'categorical':\n",
    "                padding_idx = feature_spec.get('padding_idx', None)\n",
    "                self.embedding[feature] = nn.Embedding(feature_spec['vocab_size'],\n",
    "                                                       embedding_dim,\n",
    "                                                       padding_idx=padding_idx)\n",
    "        # LR\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_map['num_fields'])\n",
    "        self.lr = nn.Linear(feature_map['num_fields'], 1)\n",
    "        # Compressed Interaction Network\n",
    "        self.cin = CompressedInteractionNet(\n",
    "            feature_map['num_fields'], cin_units, output_dim=1)\n",
    "        # Deep Neural Network\n",
    "        input_dim = feature_map['num_fields'] * embedding_dim\n",
    "        hidden_units = [input_dim] + hidden_units\n",
    "        hidden_layers = []\n",
    "        for i in range(len(hidden_units) - 1):\n",
    "            hidden_layers.append(\n",
    "                nn.Linear(hidden_units[i], hidden_units[i + 1]))\n",
    "            hidden_layers.append(nn.ReLU())\n",
    "        hidden_layers.append(nn.Linear(hidden_units[-1], 1))\n",
    "        self.dnn = nn.Sequential(*hidden_layers)\n",
    "        # Sigmoid\n",
    "        self.output_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        feature_emb_list = []\n",
    "        for feature, feature_spec in self.feature_map['feature_specs'].items():\n",
    "            if feature_spec['type'] == 'numerical':\n",
    "                raw_feature = X[:, feature_spec['index']].float().view(-1, 1)\n",
    "            elif feature_spec['type'] == 'categorical':\n",
    "                raw_feature = X[:, feature_spec['index']].long()\n",
    "            embedding_vec = self.embedding[feature](raw_feature)\n",
    "            feature_emb_list.append(embedding_vec)\n",
    "        feature_emb = torch.stack(feature_emb_list, dim=1)\n",
    "        flat_feature_emb = feature_emb.flatten(start_dim=1)\n",
    "        lr_out = self.lr(self.batch_norm(X))\n",
    "        cin_out = self.cin(feature_emb)\n",
    "        dnn_out = self.dnn(flat_feature_emb)\n",
    "        out = lr_out + cin_out + dnn_out\n",
    "        y_pred = self.output_activation(out).squeeze(1)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class CompressedInteractionNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_fields,\n",
    "                 cin_units,\n",
    "                 output_dim=1):\n",
    "        super(CompressedInteractionNet, self).__init__()\n",
    "        self.cin_units = cin_units\n",
    "        self.conv = nn.ModuleDict()\n",
    "        for i, unit in enumerate(cin_units):\n",
    "            in_channels = num_fields * \\\n",
    "                self.cin_units[i - 1] if i > 0 else num_fields ** 2\n",
    "            out_channels = unit\n",
    "            self.conv['layer_' + str(i)] = nn.Conv1d(in_channels,\n",
    "                                                     out_channels,  # how many filters\n",
    "                                                     kernel_size=1)  # kernel output shape\n",
    "        self.fc = nn.Linear(sum(cin_units), output_dim)\n",
    "\n",
    "    def forward(self, feature_emb):\n",
    "        X_0 = feature_emb\n",
    "        pooling_vec_list = []\n",
    "        batch_size = X_0.shape[0]\n",
    "        embedding_dim = X_0.shape[-1]\n",
    "        X_i = X_0\n",
    "        for i in range(len(self.cin_units)):\n",
    "            hadamard_tensor = torch.einsum('bhd,bmd->bhmd', X_0, X_i)\n",
    "            hadamard_tensor = hadamard_tensor.view(\n",
    "                batch_size, -1, embedding_dim)\n",
    "            X_i = self.conv['layer_' +\n",
    "                            str(i)](hadamard_tensor).view(batch_size, -1, embedding_dim)\n",
    "            pooling_vec_list.append(X_i.sum(dim=-1))\n",
    "        concat_vec = torch.cat(pooling_vec_list, dim=-1)\n",
    "        out = self.fc(concat_vec)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c46429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [300/1388] Loss: 0.6292\n",
      "Epoch [1/5], Step [600/1388] Loss: 0.6063\n",
      "Epoch [1/5], Step [900/1388] Loss: 0.5344\n",
      "Epoch [1/5], Step [1200/1388] Loss: 0.6174\n",
      "Epoch [2/5], Step [300/1388] Loss: 0.6643\n",
      "Epoch [2/5], Step [600/1388] Loss: 0.4939\n",
      "Epoch [2/5], Step [900/1388] Loss: 0.5171\n",
      "Epoch [2/5], Step [1200/1388] Loss: 0.4998\n",
      "Epoch [3/5], Step [300/1388] Loss: 0.5913\n",
      "Epoch [3/5], Step [600/1388] Loss: 0.5742\n",
      "Epoch [3/5], Step [900/1388] Loss: 0.5561\n",
      "Epoch [3/5], Step [1200/1388] Loss: 0.4882\n",
      "Epoch [4/5], Step [300/1388] Loss: 0.4916\n",
      "Epoch [4/5], Step [600/1388] Loss: 0.5015\n",
      "Epoch [4/5], Step [900/1388] Loss: 0.5310\n",
      "Epoch [4/5], Step [1200/1388] Loss: 0.5598\n",
      "Epoch [5/5], Step [300/1388] Loss: 0.4284\n",
      "Epoch [5/5], Step [600/1388] Loss: 0.6740\n",
      "Epoch [5/5], Step [900/1388] Loss: 0.4679\n",
      "Epoch [5/5], Step [1200/1388] Loss: 0.6481\n"
     ]
    }
   ],
   "source": [
    "model = xDeepFM(feature_map).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 300 == 0:\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\".format(\n",
    "                epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d267cb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 69.72 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device).bool()\n",
    "        output = model(X)\n",
    "        y_pred = output > 0.5\n",
    "        total += y.shape[0]\n",
    "        correct += (y_pred == y).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {:.2f} %'.format(\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42172ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbb5f3d532aec8608a2fec9573bdcbc5182a804a4738e1f49913b4f315f16aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
